{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ea9068",
   "metadata": {},
   "source": [
    "# Studying Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1e6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Used for serializing and de-serializing the model object for storing on disk\n",
    "import pickle\n",
    "\n",
    "# cv2 is importing \"opencv-python\" which are pre-built opencv moduled [!CPU Only]\n",
    "import cv2\n",
    "\n",
    "# for listing directories/files, like \"ls\" in Linux\n",
    "from os import listdir\n",
    "\n",
    "# Used to convert multi-class labels to binary labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# For creating the model layer-by-layer as it groups a linear stack of layers into a tf.keras.Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# For normalizing the non-linear input to the activation function\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# A 2D Convolution Layer that creates a convolution kernel to produce a tensor of outputs\n",
    "# https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "# https://paperswithcode.com/method/max-pooling\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "# Keras Layers \n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "\n",
    "# Exposes TensorFlow backend functions\n",
    "from keras import backend as K\n",
    "\n",
    "# Ensures that the model receives new variations of the images at each epoch\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Optimization function\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Pipeline for image processing purposes\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Converts a PIL Image instance to a Numpy array\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Converts input labels into multilabel labels (non-binary)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# For splitting dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For plots and figures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bebf81",
   "metadata": {},
   "source": [
    "# Declaring Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1284bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of passes of the entire training dataset\n",
    "EPOCHS = 20\n",
    "\n",
    "# Learning rate and Batch Size for training the model\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "# Image dimensions\n",
    "default_image_size = tuple((256, 256))\n",
    "width = height = 256\n",
    "image_size = 0\n",
    "depth=3\n",
    "\n",
    "# Path to dataset\n",
    "directory_root = \"C:\\\\Users\\\\mash0\\\\OneDrive\\\\Desktop\\\\Fallsem\\\\IMGP-CSE4019\\\\project\\\\input\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17345723",
   "metadata": {},
   "source": [
    "## Helper Function to resize and convert Images to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24dfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            image = cv2.resize(image, default_image_size)   \n",
    "            return img_to_array(image)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9420351",
   "metadata": {},
   "source": [
    "## Load all plant images and use convert_image_to_array() on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1266a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Pepper__bell___Bacterial_spot ...\n",
      "[INFO] Processing Pepper__bell___healthy ...\n",
      "[INFO] Processing Potato___Early_blight ...\n",
      "[INFO] Processing Potato___healthy ...\n",
      "[INFO] Processing Potato___Late_blight ...\n",
      "[INFO] Processing Tomato_Bacterial_spot ...\n",
      "[INFO] Processing Tomato_Early_blight ...\n",
      "[INFO] Processing Tomato_healthy ...\n",
      "[INFO] Processing Tomato_Late_blight ...\n",
      "[INFO] Processing Tomato_Leaf_Mold ...\n",
      "[INFO] Processing Tomato_Septoria_leaf_spot ...\n",
      "[INFO] Processing Tomato_Spider_mites_Two_spotted_spider_mite ...\n",
      "[INFO] Processing Tomato__Target_Spot ...\n",
      "[INFO] Processing Tomato__Tomato_mosaic_virus ...\n",
      "[INFO] Processing Tomato__Tomato_YellowLeaf__Curl_Virus ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "image_list, label_list = [], []\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    root_dir = listdir(directory_root)\n",
    "    for directory in root_dir :\n",
    "        # remove .DS_Store from list\n",
    "        if directory == \".DS_Store\" :\n",
    "            root_dir.remove(directory)\n",
    "\n",
    "    for plant_folder in root_dir :\n",
    "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "        \n",
    "        for disease_folder in plant_disease_folder_list :\n",
    "            # remove .DS_Store from list\n",
    "            if disease_folder == \".DS_Store\" :\n",
    "                plant_disease_folder_list.remove(disease_folder)\n",
    "\n",
    "        for plant_disease_folder in plant_disease_folder_list:\n",
    "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
    "                \n",
    "            for single_plant_disease_image in plant_disease_image_list :\n",
    "                if single_plant_disease_image == \".DS_Store\" :\n",
    "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
    "\n",
    "            for image in plant_disease_image_list[:200]:\n",
    "                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n",
    "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
    "                    image_list.append(convert_image_to_array(image_directory))\n",
    "                    label_list.append(plant_disease_folder)\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683d0787",
   "metadata": {},
   "source": [
    "## Generate Image Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12873be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pepper__bell___Bacterial_spot' 'Pepper__bell___healthy'\n",
      " 'Potato___Early_blight' 'Potato___Late_blight' 'Potato___healthy'\n",
      " 'Tomato_Bacterial_spot' 'Tomato_Early_blight' 'Tomato_Late_blight'\n",
      " 'Tomato_Leaf_Mold' 'Tomato_Septoria_leaf_spot'\n",
      " 'Tomato_Spider_mites_Two_spotted_spider_mite' 'Tomato__Target_Spot'\n",
      " 'Tomato__Tomato_YellowLeaf__Curl_Virus' 'Tomato__Tomato_mosaic_virus'\n",
      " 'Tomato_healthy']\n"
     ]
    }
   ],
   "source": [
    "image_size = len(image_list)\n",
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "print(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d3233",
   "metadata": {},
   "source": [
    "## Split dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d39b50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Spliting data to train, test\n"
     ]
    }
   ],
   "source": [
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0\n",
    "print(\"[INFO] Spliting data to train, test\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883926c",
   "metadata": {},
   "source": [
    "## Build the Model with desired Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "inputShape = (height, width, depth)\n",
    "chanDim = -1\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (depth, height, width)\n",
    "    chanDim = 1\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation(\"softmax\"))s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
